<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Triangle SfN 2025: Efficient and Effective 3D Visualization of Internal
      Neuroimage Structures with NiiVue
    </title>
    <script id="MathJax-script" async src="mathjax/tex-chtml.js"></script>
  </head>

  <body>
    <article class="poster">
      <header class="poster-header">
        <div class="header-title">
          <div class="logo-stacked">
            <a href="https://fideus.io" target="_blank">
              <img
                src="/src/assets/fideus-logo.svg"
                class="logo"
                alt="Fideus Labs logo"
              />
            </a>
            <a
              href="https://sc.edu/study/colleges_schools/artsandsciences/psychology/our_people/directory/rorden_chris.php"
              target="_blank"
            >
              <img
                src="/src/assets/usc-logo.svg"
                class="logo"
                alt="University of South Carolina logo"
              />
            </a>
          </div>
          <h1>
            Efficient and Effective 3D Visualization of Internal Neuroimage
            Structures with NiiVue
          </h1>

          <div class="logo-stacked">
            <a href="https://trianglesfnchapter.org" target="_blank">
              <img
                src="/src/assets/triangle-sfn.png"
                class="logo vanilla"
                alt="Triangle SfN logo"
              />
            </a>
            <a href="https://quantco.com" target="_blank">
              <img
                src="/src/assets/logo_quantco_black.svg"
                class="logo"
                alt="Quantco logo"
              />
            </a>
          </div>
        </div>

        <div class="header-subtitle">
          Triangle Society for Neuroscience 2025 Conference<br />
          <i
            >Matthew McCormick, PhD<sup>1</sup>, Taylor Hanayik,
            PhD<sup>2</sup>, and Chris Rorden, PhD<sup>3</sup></i
          ><br />
          <sup>1</sup>Fideus Labs, Research Triangle Park, NC 27709,
          <a href="mailto:matt@fideus.io"><i>matt@fideus.io</i></a
          >, <sup>2</sup>QuantCo virtual diagnostics team,
          <sup>3</sup>University of South Carolina<br />
        </div>
      </header>

      <section class="introduction">
        <p id="summary">
          A
          <strong
            >novel normalized logarithmic gradient magnitude approach</strong
          >, implemented in <strong>NiiVue</strong>, enhances
          <strong>visualization of internal structures</strong> while
          maintaining <strong>real-time performance</strong> across devices.
        </p>
        <br />
        <h2>Introduction</h2>
        <ul>
          <li>
            <strong>Neuroimaging Visualization Challenge:</strong>
            <ul>
              <li>
                Visualizing internal brain structures is critical for
                understanding complex neuroanatomy, functional relationships,
                and pathology detection.
              </li>
              <li>
                Our goal is to provide advanced visualization techniques through
                an intuitive web interface accessible to researchers without
                specialized hardware or software installations.
              </li>
            </ul>
          </li>
          <li>
            <strong>NiiVue Capabilities:</strong>
            <ul>
              <li>
                NiiVue [1] is a web-based visualization tool for neuroimaging that
                runs on any operating system and web device (phone, tablet,
                computer).
              </li>
              <li>
                Uniquely displays multiple neuroimaging datatypes
                simultaneously: voxels, meshes, tractography streamlines,
                statistical maps, and connectomes.
              </li>
            </ul>
          </li>
          <li>
            <strong>Gradient Opacity Role:</strong> Traditional volume rendering
            often obscures internal structures behind high-intensity regions;
            gradient opacity allows visualization through tissue based on
            structural boundaries. [2]
          </li>
        </ul>
      <!-- </section> -->

      <!-- <section class="methods"> -->
        <h2>Methods</h2>
        <ul>
          <li>
            <strong>Normalized Logarithmic Gradient Approach:</strong>
            <ul>
              <li>
                Applies logarithmic transformation to compress wide dynamic
                range of gradient magnitudes
              </li>
              <li>Normalizes values to range for intuitive user control
                <div>
                  $$o = \left( \log_2\left(G_x^2 + G_y^2 + G_z^2 + \frac{1}{255^2 \cdot 8}\right) + \log_2\left(\frac{1}{255^2 \cdot 8}\right) \right)^{8.0}$$
                </div>
                Where final exponentiation to 8.0 adds translucency to rendering.
              </li>
            </ul>
          </li>

          <li>
            <strong>Gradient Magnitude Calculation:</strong>
            <ul>
              <li>
                First-order gradients computed using 3D Sobel-approximation
                operators
              </li>
              <li>
                Optionally uses second-order gradients based on Taylor Series
                expansion for enhanced detail [3]:
                  \(f^1_0 = \frac{f_{-2} - 8 f_{-1} + 8 f_1 - f_2}{ 12 h }\)
              </li>
            </ul>
          </li>

          <figure class="gradient-order-figure">
            <div class="interactive-preview-container">
              <img src="/src/assets/gradient-order.png" alt="Gradient Order" />
              <div class="click-to-interact-overlay">Click to interact</div>
            </div>
            <div class="gradient-orientation-order-1">
            </div>
            <div class="gradient-orientation-order-2">
            </div>
            <figcaption>
              <i><b>Figure 1:</b> While first-order gradients are sufficient for
                orientations, second-order gradient magnitudes sometimes help
                resolve fine structural elements. Gradient orientations
                visualized on a CT brain with embedded test objects. Gradient
                Order: 1st order (top) vs. 2nd order (bottom).</i
              >
            </figcaption>
          </figure>

          <li>
            <strong>Real-Time, GPGPU Performance [4]:</strong>
            <ul>
              <li>
                Pre-computes gradients using WebGL2 fragment shaders for
                parallel processing
              </li>
              <li>
                Leverages GPU texture interpolation hardware for optimized
                sampling
              </li>
              <li>
                Encodes 3D gradient orientation and magnitude in only 4 bytes
                total per voxel
              </li>
              <li>
                One-time preprocessing cost of ~100ms for typical brain volumes
              </li>
              <li>Minimal impact on frame rate during interactive viewing</li>
            </ul>
          </li>
        </ul>

        <div id="github-links">
          <a href="https://github.com/thewtex/triangle-sfn-2025-internal-neuroimage-structures">
            <img src="/src/assets/github-qr-code.png" width="20%" alt="GitHub QR Code" />
            <img src="/src/assets/github-mark.svg" width="5%" alt="GitHub Logo" />
          </a>
        </div>
      </section>

      <section class="results">
        <h2>Results</h2>

        <figure>
          <img src="/src/assets/t1w.png" alt="T1W" />
          <div id="t1w" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 2:</b>
              T1-Weighted MRI. Gradient Opacity 0: Only external brain surface
              visible.<br> Gradient Opacity 0.5: Ventricles and major sulci become
              visible.<br> Gradient Opacity 1.0: Complete visualization of internal
              structures.
            </i>
          </figcaption>
        </figure>

        <!-- <figure>
          <img src="/src/assets/flair.png" alt="FLAIR" />
          <div id="flair" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 3:</b>
              FLAIR MRI. Emphasize gray/white matter and cortex boundaries.
            </i>
          </figcaption>
        </figure> -->

        <figure>
          <img src="/src/assets/tof.png" alt="TOF" />
          <div id="tof" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 3:</b>
              TOF MRI Angiography. Superior visualization of vascular trees
              within brain tissue.
            </i>
          </figcaption>
        </figure>

        <figure>
          <img src="/src/assets/mni152.png" alt="MNI152" />
          <div id="mni152" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 4:</b>
              MNI-152 Atlas. Enhanced definition of deep brain structures.
            </i>
          </figcaption>
        </figure>

        <figure>
          <img src="/src/assets/ct.png" alt="CT" />
          <div id="ct" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 5:</b>
              CT electrodes. Precise localization of implanted devices through
              surrounding tissue.
            </i>
          </figcaption>
        </figure>

        <figure>
          <img src="/src/assets/visiblehuman.png" alt="Visible Human" />
          <div id="visiblehuman" class="result-render">
            <div class="result-render-0">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-50">
              <canvas height="256" hidden></canvas>
            </div>
            <div class="result-render-100">
              <canvas height="256" hidden></canvas>
            </div>
          </div>
          <figcaption>
            <i
              ><b>Figure 6:</b>
              Visible Human RGB. Natural color preservation while revealing
              internal structures
            </i>
          </figcaption>
        </figure>

      </section>

      <section class="discussion">
        <h2>Discussion</h2>
        <ul>
          <li>
            <strong>Power-Law Distribution:</strong>
            Natural structures exhibit gradient magnitudes that follow power-law
            distributions following Zipf's law [6].
          </li>
          <figure>
            <div id="gradient-comparison" >
              <img
                src="/src/assets/gradient_comparison.svg"
                alt="Gradient Comparison"
                width="60%">
            </div>
            <figcaption id="gradient-comparison-figcaption">
              <i><b>Figure 7:</b>
                Comparison of gradient magnitude distributions before and after logarithmic
                transformation for various neuroimaging datasets.</i>
            </figcaption>
          </figure>
          <li>
            A <strong>logarithmic transformation</strong> is particularly
            well-suited for neuroimaging data as it:
            <ul>
              <li>Compresses the wide dynamic range of gradient magnitudes</li>
              <li>
                Emphasizes subtle structural boundaries within similar intensity
                regions
              </li>
              <li>Produces more perceptually linear visual results</li>
            </ul>
          </li>
          <li>
            <strong>Ultrasound Comparison:</strong> Similar logarithmic
            transformations are standard in B-mode ultrasound imaging, where
            power-law distributions are well-documented in tissue interactions [5].
          </li>
          <li>
            <strong>User Interface Considerations:</strong>
            <ul>
              <li>
                Single intuitive parameter (0-1 scale) controls the effect
                across all modalities
              </li>
              <li>
                Consistent behavior regardless of image resolution or intensity
                range
              </li>
              <li>
                Preserves original color mapping and intensity relationships
              </li>
            </ul>
          </li>
          <li>
            <strong>Future Directions:</strong> Implementation designed to
            handle datasets from microscopic to macroscopic scales:
            <ul>
              <li>
                Will support terabyte-scale OME-Zarr [7] imaging datasets in future
                work
              </li>

              <figure>
                <div id="lightsheet-img">
                  <img src="/src/assets/lightsheet.png" alt="OME-Zarr Human Brain Lightsheet Volume" width="40%"/>
                </div>
                <div id="ome-zarr" class="ome-zarr-render">
                  <div class="ome-zarr-render-scale-5">
                    <canvas height="256" hidden></canvas>
                  </div>
                  <div class="ome-zarr-render-scale-3">
                    <canvas height="256" hidden></canvas>
                  </div>
                  <div class="ome-zarr-render-scale-1">
                    <canvas height="256" hidden></canvas>
                  </div>
                </div>
                <figcaption>
                  <i><b>Figure 8:</b>
                    OME-Zarr lightsheet human cortex volume [8]<br> rendered at multiple scales.
                  </i>
                </figcaption>
              </figure>

              <li>
                Maintain consistent visualization from subcellular to
                whole-brain volumes [6]
              </li>
            </ul>
            Additionally, develop techniques that focus on AI-identified
            regions-of-interest with 3D context for specific research and
            clinical applications.
          </li>
        </ul>

        <!-- <h2>Conclusion</h2>
        <ul>
          <li>
            <strong>Summary:</strong> NiiVue's gradient opacity implementation
            provides an intuitive, computationally efficient method for
            visualizing internal brain structures across multiple imaging
            modalities.
          </li>
        </ul> -->
        <div class="references">
          <h3>References</h3>
          <ol>
            <li>
              NiiVue/niivue: a WebGL2 based medical image viewer. GitHub.
              (2025).
              <a href="https://github.com/niivue/niivue"
                >https://github.com/niivue/niivue</a
              >
            </li>
            <li>
              Engel, K., Hadwiger, M., Kniss, J. M., & Rezk-Salama, C. (2006). Local volume illumination. In Real-time volume graphics (pp. 47-52). Eurographics Association. Retrieved April 1, 2025, from <a href="https://webdocs.cs.ualberta.ca/~pierreb/Visualization2006/Real-Time-Volume-Rendering.pdf">https://webdocs.cs.ualberta.ca/~pierreb/Visualization2006/Real-Time-Volume-Rendering.pdf</a>
            </li>
            <li>
              Khan, IR and Ohba, Ryoji. Closed-form expressions for the finite difference approximations
of first and higher derivatives based on Taylor series. Journal of Computational and Applied
Mathematics, 107:179-193, 1999. <a href="https://doi.org/10.1016/S0377-0427(99)00088-6">https://doi.org/10.1016/S0377-0427(99)00088-6</a>.
            </li>
            <li>
              Ikits, M., Kniss, J., Lefohn, A., & Hansen, C. (2004). Volume rendering techniques. In R. Fernando (Ed.), GPU Gems: Programming Techniques, Tips, and Tricks for Real-Time Graphics (pp. 667-690). Addison-Wesley. Retrieved April 1, 2025, from <a href="https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-39-volume-rendering-techniques">https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-39-volume-rendering-techniques</a>
            </li>
            <li>
              Parker, K.J. (2022). Power laws prevail in ultrasound-tissue interactions. <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9118335/">PMC, 9118335</a>.
            </li>
            <li>
              Roman Sabin and Bertolotti Francesco (2022). A master equation for power laws. R. Soc. Open Sci.9220531. <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.220531">https://royalsocietypublishing.org/doi/10.1098/rsos.220531</a>
            </li>
            <li>
              Moore, J., Basurto-Lozada, D., Besson, S. et al. OME-Zarr: a cloud-optimized bioimaging file format with international community support. Histochem Cell Biol 160, 223-251 (2023). <a href="https://doi.org/10.1007/s00418-023-02209-1">https://doi.org/10.1007/s00418-023-02209-1</a>
            </li>
            <li>
              Kamentsky, Lee; Marx, Slayton; Park, Juhyuk; Su-Arcaro, Clover; Moukheiber, Mira; Zhao, Victor (2023) Light sheet imaging of the human brain (Version draft) [Data set]. DANDI archive. https://doi.org/10.80507/dandi.123456/0.123456.1234
            </li>
          </ol>
        </div>
      </section>

      <footer class="poster-footer">
        <div class="resources"></div>
      </footer>
    </article>
    <script type="module" src="/src/main.ts"></script>
  </body>
</html>
